{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Admission Dataset\n",
    "Zulema Caldwell\n",
    "\n",
    "Overview\n",
    "Analyze college admission data to determine admission based on GRE, GPA, and rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark...\n",
      "Spark found in :  /home/ubuntu/apps/spark\n",
      "Spark config:\n",
      "\t executor.memory=2g\n",
      "\tsome_property=some_value\n",
      "\tspark.app.name=TestApp\n",
      "\tspark.master=local[*]\n",
      "\tspark.sql.warehouse.dir=/tmp/tmp0oo_tjz9\n",
      "\tspark.submit.deployMode=client\n",
      "\tspark.submit.pyFiles=\n",
      "\tspark.ui.showConsoleProgress=true\n",
      "Spark UI running on port 4044\n"
     ]
    }
   ],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[_c0: int, site: string, source: string, label: string, toplevel: string, domain: string, words: string]\n",
      "root\n",
      " |-- admit: integer (nullable = true)\n",
      " |-- gre: integer (nullable = true)\n",
      " |-- gpa: double (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#from wordsegment import load, segment\n",
    "#load()\n",
    "\n",
    "#dga = pd.read_csv('.csv')\n",
    "\n",
    "admissionDF = spark.read.\\\n",
    "           option(\"header\", \"true\").\\\n",
    "           option(\"inferSchema\", \"true\").\\\n",
    "           csv(\"/data/college-admissions/admission-data.csv\")\n",
    "print(admissionDF)\n",
    "admissionDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----+\n",
      "|admit|gre| gpa|rank|\n",
      "+-----+---+----+----+\n",
      "|    0|380|3.61|   3|\n",
      "|    1|660|3.67|   3|\n",
      "|    1|800| 4.0|   1|\n",
      "|    0|640|3.19|   4|\n",
      "|    0|520|2.93|   4|\n",
      "|    1|760| 3.0|   2|\n",
      "|    0|560|2.98|   1|\n",
      "|    0|400|3.08|   2|\n",
      "|    0|540|3.39|   3|\n",
      "|    1|700|3.92|   2|\n",
      "|    1|800| 4.0|   4|\n",
      "|    0|440|3.22|   1|\n",
      "|    1|760| 4.0|   1|\n",
      "|    1|700|3.08|   2|\n",
      "|    1|700| 4.0|   1|\n",
      "|    0|480|3.44|   3|\n",
      "|    1|780|3.87|   4|\n",
      "|    0|360|2.56|   3|\n",
      "|    1|800|3.75|   2|\n",
      "|    0|540|3.81|   1|\n",
      "+-----+---+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "admissionDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----+\n",
      "|admit|gre| gpa|rank|\n",
      "+-----+---+----+----+\n",
      "|    0|300|2.92|   4|\n",
      "|    0|360|2.56|   3|\n",
      "|    0|360|3.14|   1|\n",
      "|    0|380|2.91|   4|\n",
      "|    0|380|2.94|   3|\n",
      "|    0|380|3.61|   3|\n",
      "|    0|400|3.05|   2|\n",
      "|    0|400|3.08|   2|\n",
      "|    0|400|3.31|   3|\n",
      "|    0|400|3.35|   3|\n",
      "|    0|400|3.65|   2|\n",
      "|    0|440|2.48|   4|\n",
      "|    0|440|3.13|   4|\n",
      "|    0|480|3.39|   4|\n",
      "|    0|480|3.57|   2|\n",
      "|    0|500|2.97|   4|\n",
      "|    0|500|3.17|   3|\n",
      "|    0|500|3.31|   3|\n",
      "|    0|520| 2.9|   3|\n",
      "|    0|520|2.93|   4|\n",
      "+-----+---+----+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+---+----+----+\n",
      "|admit|gre| gpa|rank|\n",
      "+-----+---+----+----+\n",
      "|    0|440|3.22|   1|\n",
      "|    0|480|3.44|   3|\n",
      "|    0|500|2.71|   2|\n",
      "|    0|520|3.29|   1|\n",
      "|    0|540|3.78|   4|\n",
      "|    0|560|3.32|   4|\n",
      "|    0|600|3.48|   2|\n",
      "|    0|640|3.19|   4|\n",
      "|    0|700|2.88|   2|\n",
      "|    1|500|3.13|   2|\n",
      "|    1|620|3.18|   2|\n",
      "|    1|680|3.85|   3|\n",
      "|    1|800| 4.0|   1|\n",
      "|    1|800| 4.0|   3|\n",
      "+-----+---+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "admissionTrain, admissionTest = admissionDF.randomSplit([0.8, 0.2])\n",
    "admissionTrain.show()\n",
    "admissionTest.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize 3 columns--GRE, GPA, RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----+----------------+\n",
      "|admit|gre| gpa|rank|        features|\n",
      "+-----+---+----+----+----------------+\n",
      "|    0|300|2.92|   4|[300.0,2.92,4.0]|\n",
      "|    0|360|2.56|   3|[360.0,2.56,3.0]|\n",
      "|    0|360|3.14|   1|[360.0,3.14,1.0]|\n",
      "|    0|380|2.91|   4|[380.0,2.91,4.0]|\n",
      "|    0|380|2.94|   3|[380.0,2.94,3.0]|\n",
      "|    0|380|3.61|   3|[380.0,3.61,3.0]|\n",
      "|    0|400|3.05|   2|[400.0,3.05,2.0]|\n",
      "|    0|400|3.08|   2|[400.0,3.08,2.0]|\n",
      "|    0|400|3.31|   3|[400.0,3.31,3.0]|\n",
      "|    0|400|3.35|   3|[400.0,3.35,3.0]|\n",
      "|    0|400|3.65|   2|[400.0,3.65,2.0]|\n",
      "|    0|440|2.48|   4|[440.0,2.48,4.0]|\n",
      "|    0|440|3.13|   4|[440.0,3.13,4.0]|\n",
      "|    0|480|3.39|   4|[480.0,3.39,4.0]|\n",
      "|    0|480|3.57|   2|[480.0,3.57,2.0]|\n",
      "|    0|500|2.97|   4|[500.0,2.97,4.0]|\n",
      "|    0|500|3.17|   3|[500.0,3.17,3.0]|\n",
      "|    0|500|3.31|   3|[500.0,3.31,3.0]|\n",
      "|    0|520| 2.9|   3| [520.0,2.9,3.0]|\n",
      "|    0|520|2.93|   4|[520.0,2.93,4.0]|\n",
      "+-----+---+----+----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "## TODO : create featureVector with 'mpg' and 'cyl'\n",
    "## Hint :  inputCols=['mpg', 'cyl']\n",
    "assembler = VectorAssembler(inputCols=[\"gre\", \"gpa\", \"rank\"], outputCol=\"features\")\n",
    "featureVector = assembler.transform(admissionTrain)\n",
    "featureVector.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do binary classification using LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.1, elasticNetParam=0.8, labelCol='admit')\n",
    "\n",
    "#Fit the Model\n",
    "lrModel = lr.fit(featureVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----+----------------+--------------------+--------------------+----------+\n",
      "|admit|gre| gpa|rank|        features|       rawPrediction|         probability|prediction|\n",
      "+-----+---+----+----+----------------+--------------------+--------------------+----------+\n",
      "|    0|440|3.22|   1|[440.0,3.22,1.0]|[0.00763001634508...|[0.50190749483220...|       0.0|\n",
      "|    0|480|3.44|   3|[480.0,3.44,3.0]|[0.50692614322887...|[0.62408561470433...|       0.0|\n",
      "|    0|500|2.71|   2|[500.0,2.71,2.0]|[0.14345894427855...|[0.53580335297267...|       0.0|\n",
      "|    0|520|3.29|   1|[520.0,3.29,1.0]|[-0.1349883684976...|[0.46630405923494...|       1.0|\n",
      "|    0|540|3.78|   4|[540.0,3.78,4.0]|[0.69792064616081...|[0.66772659153509...|       0.0|\n",
      "|    0|560|3.32|   4|[560.0,3.32,4.0]|[0.63127597693628...|[0.65277872976616...|       0.0|\n",
      "|    0|600|3.48|   2|[600.0,3.48,2.0]|[0.00948067491505...|[0.50237015097572...|       0.0|\n",
      "|    0|640|3.19|   4|[640.0,3.19,4.0]|[0.47567745679977...|[0.61672665095495...|       0.0|\n",
      "|    0|700|2.88|   2|[700.0,2.88,2.0]|[-0.2134115212106...|[0.44684869576694...|       1.0|\n",
      "|    1|500|3.13|   2|[500.0,3.13,2.0]|[0.17071722839543...|[0.54257595317312...|       0.0|\n",
      "|    1|620|3.18|   2|[620.0,3.18,2.0]|[-0.0467798860744...|[0.48830716074655...|       1.0|\n",
      "|    1|680|3.85|   3|[680.0,3.85,3.0]|[0.16563184009215...|[0.54131355383250...|       0.0|\n",
      "|    1|800| 4.0|   1| [800.0,4.0,1.0]|[-0.6039739008893...|[0.35343505501502...|       1.0|\n",
      "|    1|800| 4.0|   3| [800.0,4.0,3.0]|[-0.0453752067308...|[0.48865814423828...|       1.0|\n",
      "+-----+---+----+----+----------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrModel.transform(assembler.transform(admissionTest)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7093023255813954\n",
      "FPR: 0.3123725010199918\n",
      "TPR: 0.7093023255813953\n",
      "F-measure: 0.706261978965666\n",
      "Precision: 0.7081388700519899\n",
      "Recall: 0.7093023255813953\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define WSSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_wsse (predictions, model):\n",
    "    centers = model.clusterCenters()\n",
    "    \n",
    "    wssse = 0\n",
    "    for i, row in enumerate(predictions.collect()):\n",
    "        feature = row['features']\n",
    "        prediction = row['prediction']\n",
    "        center = centers[prediction]\n",
    "        diff = feature - center\n",
    "        error = np.sqrt(sum([x**2 for x in diff]))\n",
    "        wssse += error\n",
    "        # print ('row={}, feature : {} , prediction : {} , center : {},  diff : {}, error : {},  wssse={}'.\n",
    "        #      format(i, feature, prediction, center, diff, error, wssse))\n",
    "        \n",
    "    return wssse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try KMeans with WSSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.6 ms, sys: 1.93 ms, total: 9.53 ms\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time \n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "k = 2\n",
    "kmeans = KMeans().setK(k).setMaxIter(10)\n",
    "model = kmeans.fit(featureVector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----+----------------+----------+\n",
      "|admit|gre| gpa|rank|        features|prediction|\n",
      "+-----+---+----+----+----------------+----------+\n",
      "|    0|520|3.29|   1|[520.0,3.29,1.0]|         0|\n",
      "|    0|440|3.22|   1|[440.0,3.22,1.0]|         0|\n",
      "|    0|500|2.71|   2|[500.0,2.71,2.0]|         0|\n",
      "|    1|500|3.13|   2|[500.0,3.13,2.0]|         0|\n",
      "|    0|480|3.44|   3|[480.0,3.44,3.0]|         0|\n",
      "|    0|540|3.78|   4|[540.0,3.78,4.0]|         0|\n",
      "|    0|560|3.32|   4|[560.0,3.32,4.0]|         0|\n",
      "|    1|800| 4.0|   1| [800.0,4.0,1.0]|         1|\n",
      "|    0|700|2.88|   2|[700.0,2.88,2.0]|         1|\n",
      "|    1|620|3.18|   2|[620.0,3.18,2.0]|         1|\n",
      "|    0|600|3.48|   2|[600.0,3.48,2.0]|         1|\n",
      "|    1|680|3.85|   3|[680.0,3.85,3.0]|         1|\n",
      "|    1|800| 4.0|   3| [800.0,4.0,3.0]|         1|\n",
      "|    0|640|3.19|   4|[640.0,3.19,4.0]|         1|\n",
      "+-----+---+----+----+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(assembler.transform(admissionTest))\n",
    "predictions.orderBy(['prediction', 'rank']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2, wssse=694.7342494034673,  silhouette_score=0.7004089392198949\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "wssse = calculate_wsse(predictions, model)\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print (\"k={}, wssse={},  silhouette_score={}\".format(k, wssse, silhouette))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that LogisticRegression is a better prediction tool than KMeans for this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
